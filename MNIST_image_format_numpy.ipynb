{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ba3799-c3dc-483b-a67e-474db9a6c759",
   "metadata": {},
   "source": [
    "### Running MNIST model using regular Numpy and then with xlns weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c432ca3a-c71a-44b3-a4ea-1604b07355a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_mnist_data\n",
    "import mlp_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ee1981-c7b7-476b-b739-590aec41a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "003121fe-b870-45eb-9532-11132563e5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "CPU times: user 230 ms, sys: 55.7 ms, total: 286 ms\n",
      "Wall time: 286 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Retrieve the MNIST data\n",
    "mnist_train_images, mnist_train_labels, mnist_test_images, mnist_test_labels = get_mnist_data.get_mnist_data_numpy_format()\n",
    "\n",
    "# Print shape for verification\n",
    "print(mnist_train_images.shape)  # Should be (60000, 28, 28)\n",
    "print(mnist_train_labels.shape)  # Should be (60000,)\n",
    "print(mnist_test_images.shape)   # Should be (10000, 28, 28)\n",
    "print(mnist_test_labels.shape)   # Should be (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca183b3d-a19c-43b9-9e88-777823ea638b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train_images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d23897-da74-4ce6-8104-da71a78e8155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07280306 0.08740606 0.06117793 0.125009   0.10067844 0.12158931\n",
      "  0.05928076 0.08761597 0.09419805 0.19024144]]\n",
      "CPU times: user 12.1 ms, sys: 2.07 ms, total: 14.1 ms\n",
      "Wall time: 13.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load the first MNIST training image\n",
    "first_image = mnist_train_images[0].flatten().reshape(1, 784)  # Shape (1, 784)\n",
    "first_image = first_image / 255.0  # Normalize pixel values\n",
    "\n",
    "# Initialize weights\n",
    "W1 = np.random.normal(0, 0.1, (785, 100))  # Input -> Hidden\n",
    "W2 = np.random.normal(0, 0.1, (101, 10))   # Hidden -> Output\n",
    "\n",
    "# Run the feedforward pass\n",
    "Y_pred = mlp_np.feedforward(first_image, W1, W2)\n",
    "\n",
    "# Print output probabilities\n",
    "print(Y_pred)  # Shape: (10, 10), each row is a probability distribution over digits 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39468631-a98c-4e87-a86f-87c05eac296c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.sum: -238.27300574407283\n",
      "Epoch 0/100, Loss: 2.3827\n",
      "np.sum: -166.77231781809587\n",
      "np.sum: -166.87671806067607\n",
      "np.sum: -127.10971021096915\n",
      "np.sum: -88.32615405903822\n",
      "np.sum: -63.58374563533892\n",
      "np.sum: -39.272145220015034\n",
      "np.sum: -29.050736159955285\n",
      "np.sum: -26.804146582268835\n",
      "np.sum: -33.176503315968034\n",
      "np.sum: -24.664575943847268\n",
      "Epoch 10/100, Loss: 0.2466\n",
      "np.sum: -10.195587680850725\n",
      "np.sum: -6.847881657402174\n",
      "np.sum: -5.552969734005894\n",
      "np.sum: -4.707957688507854\n",
      "np.sum: -4.082115306754854\n",
      "np.sum: -3.6021248711197686\n",
      "np.sum: -3.223778084733282\n",
      "np.sum: -2.915410099249192\n",
      "np.sum: -2.6584040926002115\n",
      "np.sum: -2.442802697116406\n",
      "Epoch 20/100, Loss: 0.0244\n",
      "np.sum: -2.2583773236109987\n",
      "np.sum: -2.0985242581114263\n",
      "np.sum: -1.9597724374363623\n",
      "np.sum: -1.8381394286064106\n",
      "np.sum: -1.7302977219948872\n",
      "np.sum: -1.6340480653683502\n",
      "np.sum: -1.5471444011534805\n",
      "np.sum: -1.4685911984241027\n",
      "np.sum: -1.3968338129451356\n",
      "np.sum: -1.331552969075923\n",
      "Epoch 30/100, Loss: 0.0133\n",
      "np.sum: -1.2719941768867908\n",
      "np.sum: -1.2170288708980994\n",
      "np.sum: -1.166405521038379\n",
      "np.sum: -1.11969154465951\n",
      "np.sum: -1.076584946635803\n",
      "np.sum: -1.0363214695666199\n",
      "np.sum: -0.9988111093745575\n",
      "np.sum: -0.9639374174124837\n",
      "np.sum: -0.9312603038081974\n",
      "np.sum: -0.9006587270164188\n",
      "Epoch 40/100, Loss: 0.0090\n",
      "np.sum: -0.8718083956176638\n",
      "np.sum: -0.8446314844413217\n",
      "np.sum: -0.81906363604433\n",
      "np.sum: -0.7949107634463861\n",
      "np.sum: -0.771988534672218\n",
      "np.sum: -0.7503791632934658\n",
      "np.sum: -0.7298076145025341\n",
      "np.sum: -0.7102304731481468\n",
      "np.sum: -0.6916561285122513\n",
      "np.sum: -0.6738438245006969\n",
      "Epoch 50/100, Loss: 0.0067\n",
      "np.sum: -0.6568936139203463\n",
      "np.sum: -0.6408007560469267\n",
      "np.sum: -0.6255214659016626\n",
      "np.sum: -0.6108477980807667\n",
      "np.sum: -0.5968750751153806\n",
      "np.sum: -0.5834308293191521\n",
      "np.sum: -0.5705899111839821\n",
      "np.sum: -0.5582355024826663\n",
      "np.sum: -0.5464188825212472\n",
      "np.sum: -0.5350562112625122\n",
      "Epoch 60/100, Loss: 0.0054\n",
      "np.sum: -0.5240829118224928\n",
      "np.sum: -0.5135603744162257\n",
      "np.sum: -0.503419518886209\n",
      "np.sum: -0.49368836651344933\n",
      "np.sum: -0.48426485924722734\n",
      "np.sum: -0.47518501086964837\n",
      "np.sum: -0.4664462365951268\n",
      "np.sum: -0.4579990864342023\n",
      "np.sum: -0.4498412069627564\n",
      "np.sum: -0.441939955247585\n",
      "Epoch 70/100, Loss: 0.0044\n",
      "np.sum: -0.43432791119017705\n",
      "np.sum: -0.4269716363553413\n",
      "np.sum: -0.41984767556269353\n",
      "np.sum: -0.41294742401430484\n",
      "np.sum: -0.40626761493236857\n",
      "np.sum: -0.3997670359186897\n",
      "np.sum: -0.3934804718984404\n",
      "np.sum: -0.3873771767340318\n",
      "np.sum: -0.3814232828973912\n",
      "np.sum: -0.37566464705115016\n",
      "Epoch 80/100, Loss: 0.0038\n",
      "np.sum: -0.3700582529143501\n",
      "np.sum: -0.3646044475982828\n",
      "np.sum: -0.3593106252273324\n",
      "np.sum: -0.3541535505751767\n",
      "np.sum: -0.3491445202952205\n",
      "np.sum: -0.3442478696387563\n",
      "np.sum: -0.3394942886725266\n",
      "np.sum: -0.33486292457229194\n",
      "np.sum: -0.33034671300874685\n",
      "np.sum: -0.3259314664852089\n",
      "Epoch 90/100, Loss: 0.0033\n",
      "np.sum: -0.3216375000212113\n",
      "np.sum: -0.31744207887197196\n",
      "np.sum: -0.31336046718033195\n",
      "np.sum: -0.30937995416167924\n",
      "np.sum: -0.30547266886704916\n",
      "np.sum: -0.3016746364582886\n",
      "np.sum: -0.2979520065989234\n",
      "np.sum: -0.29432053579725137\n",
      "np.sum: -0.2907699771596615\n",
      "Predicted Label: [5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]\n",
      "True Label: [5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]\n",
      "CPU times: user 1.52 s, sys: 146 ms, total: 1.67 s\n",
      "Wall time: 228 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# ---- LOAD DATA ----\n",
    "# Select the first 100 samples for training (you can increase this)\n",
    "X_train = mnist_train_images[:100].reshape(100, 784) / 255.0  # Normalize\n",
    "Y_train = mnist_train_labels[:100]  # Labels (0-9)\n",
    "\n",
    "# ---- TRAIN MODEL ----\n",
    "W1, W2, losses = mlp_np.train_nn(X_train, Y_train, W1, W2, epochs=100, lr=0.01)\n",
    "\n",
    "# ---- TESTING ----\n",
    "# Predict the first image\n",
    "predicted_labels = mlp_np.predict(X_train[:20], W1, W2)[0:20]\n",
    "print(\"Predicted Label:\", predicted_labels)\n",
    "print(\"True Label:\", Y_train[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bcc04dc-c18b-4976-9518-d187552bc073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlns as xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4ffaa82-36bf-40df-b35f-f86a8b21e692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "[[xlnsnp([xlns(0.0896660603893914)]) xlnsnp([xlns(0.10581346708038011)])\n",
      "  xlnsnp([xlns(0.11242814195245047)]) xlnsnp([xlns(0.09837844510378241)])\n",
      "  xlnsnp([xlns(0.09946285676511078)]) xlnsnp([xlns(0.09522885768438781)])\n",
      "  xlnsnp([xlns(0.08919378748964538)]) xlnsnp([xlns(0.09498263379288038)])\n",
      "  xlnsnp([xlns(0.11001047548333014)]) xlnsnp([xlns(0.1048352931814453)])]]\n",
      "CPU times: user 4.56 s, sys: 7 ms, total: 4.56 s\n",
      "Wall time: 4.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load the first MNIST training image\n",
    "first_image = mnist_train_images[0].flatten().reshape(1, 784)  # Shape (1, 784)\n",
    "first_image = first_image / 255.0  # Normalize pixel values\n",
    "\n",
    "# Initialize weights\n",
    "W1 = xl.xlnsnp(np.random.normal(0, 0.1, (785, 100)))  # Input -> Hidden\n",
    "W2 = xl.xlnsnp(np.random.normal(0, 0.1, (101, 10)))   # Hidden -> Output\n",
    "\n",
    "# Run the feedforward pass\n",
    "Y_pred = mlp_np.feedforward(first_image, W1, W2)\n",
    "\n",
    "# Print output probabilities\n",
    "print(Y_pred)  # Shape: (10, 10), each row is a probability distribution over digits 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4626fc48-49c4-42c4-868c-89d90e26e395",
   "metadata": {},
   "source": [
    "We can see that we were able to do the basic feedforward steps using weights in the xlnsnp format\n",
    "when the input data (first image) is a numpy format with datatype uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "446dbff6-dc6d-4c1e-bef5-2af252b9a1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "nonscalar comparison\n",
      "np.sum: [xlns(-11.71025909405102)]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'xlnsnp' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:12\u001b[0m\n",
      "File \u001b[0;32m~/Documents/JupyterProjects/log_number_system_alaska/mlp_np.py:77\u001b[0m, in \u001b[0;36mtrain_nn\u001b[0;34m(X, Y, W1, W2, epochs, lr)\u001b[0m\n\u001b[1;32m     74\u001b[0m dL_dW2 \u001b[38;5;241m=\u001b[39m H_bias\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m dL_dZ2  \u001b[38;5;66;03m# (101, 10)\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Backpropagate to hidden layer\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m dL_dH \u001b[38;5;241m=\u001b[39m dL_dZ2 \u001b[38;5;241m@\u001b[39m \u001b[43mW2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m  \u001b[38;5;66;03m# (batch_size, 101)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m dL_dH \u001b[38;5;241m=\u001b[39m dL_dH[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Remove bias gradient\u001b[39;00m\n\u001b[1;32m     79\u001b[0m dL_dZ1 \u001b[38;5;241m=\u001b[39m dL_dH \u001b[38;5;241m*\u001b[39m relu_derivative(Z1)  \u001b[38;5;66;03m# (batch_size, 100)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'xlnsnp' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# ---- LOAD DATA ----\n",
    "# Select the first 100 samples for training (you can increase this)\n",
    "n_samples = 5\n",
    "X_train = mnist_train_images[:n_samples].reshape(n_samples, 784) / 255.0  # Normalize\n",
    "Y_train = mnist_train_labels[:n_samples]  # Labels (0-9)\n",
    "\n",
    "# Initialize weights\n",
    "W1 = xl.xlnsnp(np.random.normal(0, 0.1, (785, 100)))  # Input -> Hidden\n",
    "W2 = xl.xlnsnp(np.random.normal(0, 0.1, (101, 10)))   # Hidden -> Output\n",
    "\n",
    "# ---- TRAIN MODEL ----\n",
    "W1, W2, losses = mlp_np.train_nn(X_train, Y_train, W1, W2, epochs=100, lr=0.01)\n",
    "\n",
    "# ---- TESTING ----\n",
    "# Predict the first image\n",
    "predicted_labels = mlp_np.predict(X_train[:20], W1, W2)[0:20]\n",
    "print(\"Predicted Label:\", predicted_labels)\n",
    "print(\"True Label:\", Y_train[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d070f1-926e-4ae5-9621-6d88523cbc0d",
   "metadata": {},
   "source": [
    "We can see that an error was produced from trying to transpose the xlnsnp data format.\n",
    "This used the defective cross_entropy_loss_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5989aded-53a9-4f52-bd7c-fd33851a4986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
